{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29877bf5-6f42-4799-ae78-b4763ed41d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\srini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2025-08-31 10:55:58.129 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.141 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.146 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.149 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.152 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.157 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.284 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.287 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.338 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.346 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.348 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 10:55:58.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# ======================== IMPORT LIBRARIES ========================\n",
    "import re\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import docx2txt\n",
    "import pdfplumber\n",
    "import PyPDF2\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# Download nltk stopwords if not already\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# ======================== STREAMLIT UI ========================\n",
    "st.title(\"RESUME CLASSIFICATION\")\n",
    "st.markdown('<style>h1{color: Purple;}</style>', unsafe_allow_html=True)\n",
    "st.subheader(\"Welcome to Resume Classification App\")\n",
    "\n",
    "# ======================== FUNCTIONS ========================\n",
    "def preprocess(text):\n",
    "    \"\"\"Clean and preprocess text\"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'<.*?>', '', text)  # remove HTML tags\n",
    "    text = re.sub(r'http\\S+', '', text)  # remove URLs\n",
    "    text = re.sub(r'[0-9]+', '', text)  # remove numbers\n",
    "\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered = [w for w in tokens if w not in stopwords.words('english') and len(w) > 2]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = [lemmatizer.lemmatize(w) for w in filtered]\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "def extract_skills(resume_text):\n",
    "    \"\"\"Extract skills from resume using skills CSV\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(\"clean_resume_data.csv\")\n",
    "        skills_list = list(data.columns.values)\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Skills CSV file not found!\")\n",
    "        return []\n",
    "\n",
    "    nlp_text = nlp(resume_text)\n",
    "    tokens = [token.text.lower() for token in nlp_text if not token.is_stop]\n",
    "    noun_chunks = [chunk.text.lower().strip() for chunk in nlp_text.noun_chunks]\n",
    "\n",
    "    skillset = set()\n",
    "    for token in tokens + noun_chunks:\n",
    "        if token in skills_list:\n",
    "            skillset.add(token)\n",
    "    return [i.capitalize() for i in skillset]\n",
    "\n",
    "def extract_text(file):\n",
    "    \"\"\"Extract text from uploaded resume\"\"\"\n",
    "    full_text = \"\"\n",
    "    if file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
    "        full_text = docx2txt.process(file)\n",
    "    elif file.type == \"application/pdf\":\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                full_text += page.extract_text() or \"\"\n",
    "    return full_text\n",
    "\n",
    "# ======================== LOAD MODEL & VECTORIZER ========================\n",
    "try:\n",
    "    model = pickle.load(open(\"modelSVM.pkl\", \"rb\"))\n",
    "    vectorizer = pickle.load(open(\"vector.pkl\", \"rb\"))\n",
    "except FileNotFoundError:\n",
    "    st.error(\"Model or vectorizer pickle file not found!\")\n",
    "\n",
    "# ======================== FILE UPLOADER ========================\n",
    "uploaded_files = st.file_uploader(\"Upload Your Resumes\", type=[\"pdf\", \"docx\"], accept_multiple_files=True)\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"File Name\", \"Predicted Profile\", \"Skills\"])\n",
    "\n",
    "if uploaded_files:\n",
    "    for file in uploaded_files:\n",
    "        file_name = file.name\n",
    "        raw_text = extract_text(file)\n",
    "        cleaned_text = preprocess(raw_text)\n",
    "        prediction = model.predict(vectorizer.transform([cleaned_text]))[0]\n",
    "        skills = extract_skills(raw_text)\n",
    "        results_df = results_df.append({\n",
    "            \"File Name\": file_name,\n",
    "            \"Predicted Profile\": prediction,\n",
    "            \"Skills\": skills\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    st.subheader(\"Classification Results\")\n",
    "    st.table(results_df)\n",
    "\n",
    "# ======================== FILTER BY ROLE ========================\n",
    "roles = [\"PeopleSoft\", \"SQL Developer\", \"React JS Developer\", \"Workday\"]\n",
    "selected_role = st.selectbox(\"Filter by Role\", roles)\n",
    "\n",
    "if not results_df.empty:\n",
    "    st.subheader(f\"Resumes for {selected_role}\")\n",
    "    st.table(results_df[results_df[\"Predicted Profile\"] == selected_role])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "f7edcfe5-a7f4-487a-8b38-9de70cd4c67a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
